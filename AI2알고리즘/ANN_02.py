import numpy as np
#numpy 모듈을 불러오고 numpy 모듈의 별칭으로 np를 지정함.

#---고정 값---
alpha = 0.1
#학습률 a(알파)를 뜻한다.
theta = 0.2
#임계값 𝜃(세타)를 뜻한다.
#임계값 : 범위를 지정하였다고 생각하면 된다.

epochs = 6
#실험에 사용된 데이터를 epochs(에폭)이라고 한다.
#6이라고 설정했지만 for문에서 6미만일 때를 표현하기 위해서 6이라고 지정했다.
#5세트가 들어오게끔 설정하였다.

x_1_weight = 0.3
#x_1의 가중치를 뜻한다.
#이때 x_2 데이터의 가중치는 0.3로 설정하였다.

x_2_weight = -0.1
#x_2의 가중치를 뜻한다.
#이때 x_2 데이터의 가중치는 -0.1로 설정하였다.

#AND 연산자 입력값과 출력 값을 설정
x_1 = np.array([0,0,1,1])
#x_1의 입력 값
#1차원 배열로 x_1의 입력 값을 0,0,1,1로 설정하였다.
x_2 = np.array([0,1,0,1])
#x_2의 입력 값
#1차원 배열로 x_2의 입력 값을 0,1,0,1로 설정하였다.
y_d = np.array([0,0,0,1])
#목표(출력) 값
#1차원 배열로 y_d의 목표 값을 0,0,0,1로 설정하였다.
#데이터의 y_Destination(목표)을 뜻한다.

#가중치는 데이터가 2개가 들어와서 2개의 가중치만 선언해 주었다.
#만약 데이터가 n개일 경우 가중치도 n개로 만들어준다.

print("Epoch\tx1\tx2\ty_d(목표)\tx_1가중치\tx_2가중치\tY_out(실제 예측 값)\tY_pred(예측 출력 값)\tError(에러)\t최종x_1가중치\t최종x_2가중치")
#출력문
#print()함수를 출력했다.
#인자값 \t : 한탭 띄어쓰기 역할을 담당한다.
for i in range(1,epochs,1):
    #총 5세트가 실행되게끔 for문을 실행시켜주었다.
    print(i,end='')
    #epochs 몇 세트인지 알려주는 i
    #기본적으로 print() 함수는 기본 값으로 줄넘김이 자동으로 설정되어 있다.
    #end = '' 인자값은 print() 함수의 줄넘김을 없애기 위한 인자값이다.
    for j in range(0,4,1):
        #모델이 예측한 값을 보여주기 위한 for문
        Y_out = ((x_1[j]*x_1_weight)+(x_2[j]*x_2_weight)-theta)
        #(x_1입력 값 * x_1입력 값의 가중치)+(x_2입력 값 * x_2입력 값의 가중치)-임계 값을 계산한 결과이다. 
        #Y_out = 모델이 예측 한 값
        if Y_out >= 0:#만약 Y_out 값이 0보다 크거나 같다면
            y_pred = 1#모델이 예측한 출력 값을 1으로 설정한다.
            #y_pred = 실제 예측 출력 값
        else:#그렇지 않다면
            y_pred = 0#모델이 예측한 출력 값을 0으로 설정한다.
            #현재 모델이 예측한 출력 값
            #y_pred = 실제 예측 출력 값
        Error = y_d[j] - y_pred
        #에러 판별 = 정답 데이터 - 실제 데이터
        #Error = 0 – 1 = -1
        #3번째 데이터의 에러를 계산했다.
        print("\t",x_1[j],"\t",x_2[j],"\t",y_d[j],"\t\t",x_1_weight,"\t\t",x_2_weight,"\t\t",round(Y_out,1),"\t\t\t",y_pred,"\t\t\t",Error,'\t\t',end='')
        x_1_weight = round(x_1_weight + alpha * x_1[j] * Error,1)
        #x_1의 가중치를 업데이트 해준다.
        #기존의 x_1의 가중치 + alpha(학습률) * x_1[j](x_1입력 데이터) * Error(오차)
        #(0.3 + 0.1 * 1 * (-1)) = 0.2
        #round() 함수를 이용해서 소수점 1번째 자리까지만 출력되게 만들었다.
        #예를 들면 round(3.147592,1) 이렇게 설정한다면 첫 번째 인자 값의 소수점을 1번째 자리만 보여주도록 만든다.
        #3.1이 보여지게 된다.
        x_2_weight = round(x_2_weight + alpha * x_2[j] * Error,1)
        #x_2의 가중치를 업데이트 해준다.
        #기존의 x_2의 가중치 + alpha(학습률) * x_2[j](x_2입력 데이터) * Error(오차)
        #(-0.1 + 0.1 * 0 * (-1)) = -0.1
        #round() 함수를 이용해서 소수점 1번째 자리까지만 출력되게 만들었다.
        print(x_1_weight,"     \t",x_2_weight)
    print()

