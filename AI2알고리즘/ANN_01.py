#---고정 값---
alpha = 0.1
#학습률 a(알파)를 뜻한다.
theta = 0.2
#임계값 𝜃(세타)를 뜻한다.
#임계값 : 범위를 지정하였다고 생각하면 된다.

x_1 = 1
#3번째 데이터의 x_1의 입력 값
#지금은 3번째 데이터 가중치만 변화되는지를 보여주기 위해 1으로 지정하였다.
x_2 = 0
#3번째 데이터의 x_2의 입력 값
#지금은 3번째 데이터 가중치만 변화되는지를 보여주기 위해 0으로 지정하였다.
y_d = 0
#3번째 데이터의 정답(출력) 값
#y_Destination(목표)을 뜻한다.
#지금은 3번째 데이터 가중치만 변화되는지를 보여주기 위해 0으로 지정하였다.

x_1_weight = 0.3
#x_1의 가중치를 뜻한다.
#x_2 데이터의 가중치는 0.3로 설정하였다.

x_2_weight = -0.1
#x_2의 가중치를 뜻한다.
#x_2 데이터의 가중치는 -0.1로 설정하였다.

#가중치는 데이터가 2개가 들어와서 2개의 가중치만 선언해 주었다.
#만약 데이터가 n개일 경우 가중치도 n개로 만들어준다.

print("Epoch\tx1\tx2\ty_d(목표)\tx_1가중치\tx_2가중치\tY_out(실제 예측 값)\tY_pred(예측 출력 값)\tError(에러)\t최종x_1가중치\t최종x_2가중치")
#출력문
Y_out = ((x_1*x_1_weight)+(x_2*x_2_weight)-theta)
#(x_1입력 값 * x_1입력 값의 가중치)+(x_2입력 값 * x_2입력 값의 가중치)-임계 값을 계산한 결과이다. 
#Y_out = (1*0.3)+(0*-0.1)+(-0.2) = 0.1
#모델이 예측한 값은 0.1이다.
if Y_out >= 0:#만약 Y_out의 값이 0보다 크거나 같다면
    y_pred = 1#모델이 예측한 출력 값을 1으로 설정한다.
    #y_pred = 실제 예측 값
else:#그렇지 않다면
    y_pred = 0#모델이 예측한 출력 값을 0으로 설정한다.
    #현재 모델이 예측한 출력 값
    #y_pred = 실제 예측 값
Error = y_d - y_pred
#에러 판별 = 정답 데이터 - 실제 예측 데이터
#Error = 0 - 1 = -1
print("\t",x_1,"\t",x_2,"\t",y_d,"\t\t",x_1_weight,"\t\t",x_2_weight,"\t\t",round(Y_out,1),"\t\t\t",y_pred,"\t\t\t",Error,'\t\t',end='')

x_1_weight = round(x_1_weight + alpha * x_1 * Error,1)
#x_1의 가중치를 업데이트 해준다.
#기존의 x_1의 가중치 + alpha(학습률) * x_1(x_1입력 데이터) * Error(오차)
#0.3 + 0.1 * 1 * (-1) = 0.2
#새로운 가중치는 0.2가 된다.
#round() 함수를 이용해서 소수점 1번째 자리 까지만 출력되게 만들었다.
#round(3.147592,1) 이렇게 설정한다면 첫번째 인자 값의 소수점을 1번째 자리만 보여주도록 만든다. 
#3.1이 보여지게 된다.
x_2_weight = round(x_2_weight + alpha * x_2 * Error,1)
#x_2의 가중치를 업데이트 해준다.
#기존의 x_2의 가중치 + alpha(학습률) * x_2(x_2입력 데이터) * Error(오차)
#-0.1 + 0.1 * 0 * (-1) = -0.1
#round() 함수를 이용해서 소수점 1번째 자리 까지만 출력되게 만들었다.

print(x_1_weight,"     \t",x_2_weight)
